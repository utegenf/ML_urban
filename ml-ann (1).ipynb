{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import IPython.display\nimport librosa\nimport librosa.display\nimport pandas as pd\nimport os\nimport struct\nimport glob\nimport soundfile as sf\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import specgram\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint \nfrom datetime import datetime\nfrom sklearn import metrics \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten,Activation, Dense, Dropout, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T15:23:25.874858Z","iopub.execute_input":"2022-02-20T15:23:25.875161Z","iopub.status.idle":"2022-02-20T15:23:25.886299Z","shell.execute_reply.started":"2022-02-20T15:23:25.875121Z","shell.execute_reply":"2022-02-20T15:23:25.885480Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Audio files and CSV file containing metadata\nfile_path = '../input/urbansound8k'\nurbansound8k = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T15:23:25.890062Z","iopub.execute_input":"2022-02-20T15:23:25.890283Z","iopub.status.idle":"2022-02-20T15:23:25.954992Z","shell.execute_reply.started":"2022-02-20T15:23:25.890256Z","shell.execute_reply":"2022-02-20T15:23:25.954068Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nurbansound8k.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T15:23:25.956306Z","iopub.execute_input":"2022-02-20T15:23:25.956626Z","iopub.status.idle":"2022-02-20T15:23:25.978262Z","shell.execute_reply.started":"2022-02-20T15:23:25.956591Z","shell.execute_reply":"2022-02-20T15:23:25.977595Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Feature extraction using librosa\ndef features_extract(file):\n    # load the audio file\n    audio,sample_rate = librosa.load(file_name,res_type='kaiser_fast')\n    \n    # extract the features\n    feature = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n    feature_norm = (feature - feature.mean())/feature.std()\n    \n    # feature scaling\n    scaled_feature = np.mean(feature_norm.T,axis=0)\n    \n    # return the scaled features\n    return scaled_feature\n\n# list containg all the features\nextracted = []\n\n# for each row in the csv\nfor index_num,row in tqdm(urbansound8k.iterrows()):\n    \n    # get the file \n    file_name = os.path.join(os.path.abspath(file_path),'fold'+str(row[\"fold\"])+'/',str(row['slice_file_name']))\n    \n    # get file label\n    final_class_labels = row['class']\n    \n    # extract feature\n    data= features_extract(file_name)\n    \n    # store it in a list\n    extracted.append([data,final_class_labels])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T15:54:27.058844Z","iopub.execute_input":"2022-02-20T15:54:27.059285Z","iopub.status.idle":"2022-02-20T16:04:58.431370Z","shell.execute_reply.started":"2022-02-20T15:54:27.059257Z","shell.execute_reply":"2022-02-20T16:04:58.429112Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Creating DataFrame from the extracted features:\ndf_extracted = pd.DataFrame(extracted,columns=['feature','label'])\n\n# Adding 'fold' column to new DataFrame which contains extracted feature and label\ndf_extracted['fold'] = urbansound8k['fold']\ndf_extracted.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:08:34.553629Z","iopub.execute_input":"2022-02-20T16:08:34.553914Z","iopub.status.idle":"2022-02-20T16:08:34.575347Z","shell.execute_reply.started":"2022-02-20T16:08:34.553884Z","shell.execute_reply":"2022-02-20T16:08:34.573967Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Constructing ANN model:\nle = LabelEncoder()\ny = np.array(df_extracted.label.tolist())\n\nfilter_size = 3\ny = np_utils.to_categorical(le.fit_transform(y))\n\nnum_labels = y.shape[1]\n\n# build model\nmodel = Sequential()\nmodel.add(Dense(512, input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128))\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy'],\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:08:38.517906Z","iopub.execute_input":"2022-02-20T16:08:38.518964Z","iopub.status.idle":"2022-02-20T16:08:38.593274Z","shell.execute_reply.started":"2022-02-20T16:08:38.518870Z","shell.execute_reply":"2022-02-20T16:08:38.592298Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_data = df_extracted[(df_extracted[\"fold\"] < 5) | (df_extracted[\"fold\"] == 6)] \nvalidation_data = df_extracted[(df_extracted[\"fold\"] == 5) | (df_extracted[\"fold\"] >= 7)]\nprint(\"Train the model on folds: \" + str([i for i in sorted(train_data[\"fold\"].unique())]))\nprint(\"Test the model on folds: \" + str([i for i in sorted(validation_data[\"fold\"].unique())]))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:23.296391Z","iopub.execute_input":"2022-02-20T16:50:23.296746Z","iopub.status.idle":"2022-02-20T16:50:23.305781Z","shell.execute_reply.started":"2022-02-20T16:50:23.296723Z","shell.execute_reply":"2022-02-20T16:50:23.304996Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"predicted = []\nactual = []\n\nfor i in range(1,11):\n    validation_data = df_extracted[df_extracted['fold'] == i]\n    train_data = df_extracted[df_extracted['fold'] != i]\n    \n    x = np.array(train_data.feature.tolist())\n    y = np.array(train_data.label.tolist())\n    \n    x_val = np.array(validation_data.feature.tolist())\n    y_val = np.array(validation_data.label.tolist())\n    \n    y = np_utils.to_categorical(le.fit_transform(y))\n    y_val = np_utils.to_categorical(le.fit_transform(y_val))\n    \n    fitting = model.fit(x, y, batch_size=64, epochs=10, validation_data=(x_val, y_val), shuffle=False)\n    pred = model.predict(x_val)\n    \n    predicted.append(pred)\n    actual.append(y_val)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:45.766642Z","iopub.execute_input":"2022-02-20T16:50:45.767057Z","iopub.status.idle":"2022-02-20T16:52:13.278085Z","shell.execute_reply.started":"2022-02-20T16:50:45.767017Z","shell.execute_reply":"2022-02-20T16:52:13.277241Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"acc = []\nfor i in range(0,10):\n    predict_conv = np.argmax(predicted[i],axis=1)\n    actual_conv = np.argmax(actual[i],axis=1)\n    acc.append(accuracy_score(actual_conv,predict_conv))\nprint(\"Accuracy for 10 fold cross validation:\",np.mean(acc))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:53:51.070272Z","iopub.execute_input":"2022-02-20T16:53:51.070563Z","iopub.status.idle":"2022-02-20T16:53:51.079252Z","shell.execute_reply.started":"2022-02-20T16:53:51.070521Z","shell.execute_reply":"2022-02-20T16:53:51.078556Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# Plotting ANN Loss\nmetrics = fitting.history\nplt.plot(fitting.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['train_loss', 'test_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.show()\n\n#ANN Accuracy\nplt.plot(fitting.history['accuracy'], label='train_accuracy')\nplt.plot(fitting.history['val_accuracy'], label='test_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:53:57.067049Z","iopub.execute_input":"2022-02-20T16:53:57.067307Z","iopub.status.idle":"2022-02-20T16:53:57.484172Z","shell.execute_reply.started":"2022-02-20T16:53:57.067282Z","shell.execute_reply":"2022-02-20T16:53:57.483409Z"},"trusted":true},"execution_count":89,"outputs":[]}]}